%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%Chapeter 1%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@article{gellmann1961eight,
title = {THE EIGHTFOLD WAY: A THEORY OF STRONG INTERACTION SYMMETRY},
author = {Gell-Mann, M},
abstractNote = {A new model of the higher symmetry of elementary particles is introduced ln which the eight known baryons are treated as a supermultiplet, degenerate in the limit of unitary symmetry but split into isotopic spin multiplets by a symmetry-breaking term. The symmetry violation is sscribed phenomenologically to the mass differences. The baryons correspond to an eight-dimensional irreducible representation of the unitary group. The pion and K meson fit into a similar set of eight particles along with a predicted pseudoscalar meson X/sup o/ having I = 0. A ninth vector meson coupled to the baryon current can be accomodated natarally in the scheme. It is predicted that the eight baryons should all have the same spin and parity and that pseudoscalar and vector mesons should form octets with possible additional singlets. The mathematics of the unitary group is described by considering three fictitious leptons, nu , e/sup -/ , and mu /sup -/, which may throw light on the structure of weak interactions. (D. L.C.)},
doi = {10.2172/4008239},
url = {https://www.osti.gov/biblio/4008239}, 
journal = {},
place = {United States},
year = {1961},
month = {3},
}
@article{laskin2020reinforcement,
  title={Reinforcement learning with augmented data},
  author={Laskin, Misha and Lee, Kimin and Stooke, Adam and Pinto, Lerrel and Abbeel, Pieter and Srinivas, Aravind},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={19884--19895},
  year={2020},
}
@ARTICLE{yijion2020invariant,
  author={Lin, Yijiong and Huang, Jiancong and Zimmer, Matthieu and Guan, Yisheng and Rojas, Juan and Weng, Paul},
  journal={IEEE Robotics and Automation Letters}, 
  title={Invariant Transform Experience Replay: Data Augmentation for Deep Reinforcement Learning}, 
  year={2020},
  volume={5},
  number={4},
  pages={6615-6622},
  doi={10.1109/LRA.2020.3013937}
}
  
@article{wang2022so2,
  title={$$\backslash$mathrm $\{$SO$\}$(2) $-Equivariant Reinforcement Learning},
  author={Wang, Dian and Walters, Robin and Platt, Robert},
  journal={arXiv preprint arXiv:2203.04439},
  year={2022}
}

@article{mondal2020group,
  title={Group equivariant deep reinforcement learning},
  author={Mondal, Arnab Kumar and Nair, Pratheeksha and Siddiqi, Kaleem},
  journal={arXiv preprint arXiv:2007.03437},
  year={2020}
}
@inproceedings{cohen2016group,
  title={Group equivariant convolutional networks},
  author={Cohen, Taco and Welling, Max},
  booktitle={International conference on machine learning},
  pages={2990--2999},
  year={2016},
  organization={PMLR}
}
@ARTICLE{lecun1989backprop,
  author={LeCun, Y. and Boser, B. and Denker, J. S. and Henderson, D. and Howard, R. E. and Hubbard, W. and Jackel, L. D.},
  journal={Neural Computation}, 
  title={Backpropagation Applied to Handwritten Zip Code Recognition}, 
  year={1989},
  volume={1},
  number={4},
  pages={541-551},
  doi={10.1162/neco.1989.1.4.541}
},

@article{ravindran2003smdp,
  title={SMDP homomorphisms: An algebraic approach to abstraction in semi markov decision processes},
  author={Ravindran, Balaraman},
  year={2003}
}
@inproceedings{ravindran2001SymmetriesAM,
  title={Symmetries and Model Minimization in Markov Decision Processes},
  author={Balaraman Ravindran and Andrew G. Barto},
  year={2001}
}
@ARTICLE{Bel,
    author = "Richard Bellman",
     title = "A Markovian Decision Process",
   journal = "Indiana Univ. Math. J.",
  fjournal = "Indiana University Mathematics Journal",
    volume = 6,
      year = 1957,
     issue = 4,
     pages = "679--684",
      issn = "0022-2518",
     coden = "IUMJAB",
   mrclass = "",
}
@inproceedings{Howard1960DynamicPA,
  title={Dynamic Programming and Markov Processes},
  author={Ronald A. Howard},
  year={1960}
}
@article{https://doi.org/10.48550/arxiv.1602.01783,
  doi = {10.48550/ARXIV.1602.01783},
  
  url = {https://arxiv.org/abs/1602.01783},
  
  author = {Mnih, Volodymyr and Badia, Adrià Puigdomènech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy P. and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Asynchronous Methods for Deep Reinforcement Learning},
  
  publisher = {arXiv},
  
  year = {2016},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%Literature review%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
@misc{vanderpol_2020_mdp_homomorphic,
  doi = {10.48550/ARXIV.2006.16908},
  url = {https://arxiv.org/abs/2006.16908},
  author = {van der Pol, Elise and Worrall, Daniel E. and van Hoof, Herke and Oliehoek, Frans A. and Welling, Max},
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {MDP Homomorphic Networks: Group Symmetries in Reinforcement Learning},
  publisher = {arXiv},
  year = {2020},
  copyright = {arXiv.org perpetual, non-exclusive license},
}


@article{zhou2020meta,
  title={Meta-learning symmetries by reparameterization},
  author={Zhou, Allan and Knowles, Tom and Finn, Chelsea},
  journal={arXiv preprint arXiv:2007.02933},
  year={2020}
}

@misc{DDPG,
  doi = {10.48550/ARXIV.1509.02971},
  
  url = {https://arxiv.org/abs/1509.02971},
  
  author = {Lillicrap, Timothy P. and Hunt, Jonathan J. and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Continuous control with deep reinforcement learning},
  
  publisher = {arXiv},
  
  year = {2015},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}
@misc{generalised_advantage,
  doi = {10.48550/ARXIV.1506.02438},
  
  url = {https://arxiv.org/abs/1506.02438},
  
  author = {Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael and Abbeel, Pieter},
  
  keywords = {Machine Learning (cs.LG), Robotics (cs.RO), Systems and Control (eess.SY), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering},
  
  title = {High-Dimensional Continuous Control Using Generalized Advantage Estimation},
  
  publisher = {arXiv},
  
  year = {2015},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@InProceedings{kondor_2018_equiv,
  title = 	 {On the Generalization of Equivariance and Convolution in Neural Networks to the Action of Compact Groups},
  author =       {Kondor, Risi and Trivedi, Shubhendu},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {2747--2755},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {10--15 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/kondor18a/kondor18a.pdf},
  url = 	 {https://proceedings.mlr.press/v80/kondor18a.html},
  abstract = 	 {Convolutional neural networks have been extremely successful in the image recognition domain because they ensure equivariance with respect to translations. There have been many recent attempts to generalize this framework to other domains, including graphs and data lying on manifolds. In this paper we give a rigorous, theoretical treatment of convolution and equivariance in neural networks with respect to not just translations, but the action of any compact group. Our main result is to prove that (given some natural constraints) convolutional structure is not just a sufficient, but also a necessary condition for equivariance to the action of a compact group. Our exposition makes use of concepts from representation theory and noncommutative harmonic analysis and derives new generalized convolution formulae.}
}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%