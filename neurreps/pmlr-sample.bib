@article{gellmann1961eight,
  title = {THE EIGHTFOLD WAY: A THEORY OF STRONG INTERACTION SYMMETRY},
  author = {Gell-Mann, M},
  abstractnote = {A new model of the higher symmetry of elementary particles is
                  introduced ln which the eight known baryons are treated as a
                  supermultiplet, degenerate in the limit of unitary symmetry but
                  split into isotopic spin multiplets by a symmetry-breaking
                  term. The symmetry violation is sscribed phenomenologically to
                  the mass differences. The baryons correspond to an
                  eight-dimensional irreducible representation of the unitary
                  group. The pion and K meson fit into a similar set of eight
                  particles along with a predicted pseudoscalar meson X/sup o/
                  having I = 0. A ninth vector meson coupled to the baryon
                  current can be accomodated natarally in the scheme. It is
                  predicted that the eight baryons should all have the same spin
                  and parity and that pseudoscalar and vector mesons should form
                  octets with possible additional singlets. The mathematics of
                  the unitary group is described by considering three fictitious
                  leptons, nu , e/sup -/ , and mu /sup -/, which may throw light
                  on the structure of weak interactions. (D. L.C.)},
  doi = {10.2172/4008239},
  url = {https://www.osti.gov/biblio/4008239},
  place = {United States},
  year = {1961},
  month = {3},
}

@article{wang2022so2,
  title = {so2-Equivariant Reinforcement Learning},
  author = {Wang, Dian and Walters, Robin and Platt, Robert},
  journal = {arXiv preprint arXiv:2203.04439},
  year = {2022},
}
@article{laskin2020reinforcement,
  title = {Reinforcement learning with augmented data},
  author = {Laskin, Misha and Lee, Kimin and Stooke, Adam and Pinto, Lerrel and
            Abbeel, Pieter and Srinivas, Aravind},
  journal = {Advances in neural information processing systems},
  volume = {33},
  pages = {19884--19895},
  year = {2020},
}
@article{yijion2020invariant,
  author = {Lin, Yijiong and Huang, Jiancong and Zimmer, Matthieu and Guan,
            Yisheng and Rojas, Juan and Weng, Paul},
  journal = {IEEE Robotics and Automation Letters},
  title = {Invariant Transform Experience Replay: Data Augmentation for Deep
           Reinforcement Learning},
  year = {2020},
  volume = {5},
  number = {4},
  pages = {6615-6622},
  doi = {10.1109/LRA.2020.3013937},
}

@article{mondal2020group,
  title = {Group equivariant deep reinforcement learning},
  author = {Mondal, Arnab Kumar and Nair, Pratheeksha and Siddiqi, Kaleem},
  journal = {arXiv preprint arXiv:2007.03437},
  year = {2020},
}
@inproceedings{cohen2016group,
  title = {Group equivariant convolutional networks},
  author = {Cohen, Taco and Welling, Max},
  booktitle = {International conference on machine learning},
  pages = {2990--2999},
  year = {2016},
  organization = {PMLR},
}

}
@article{lecun1989backprop,
  author = {LeCun, Y. and Boser, B. and Denker, J. S. and Henderson, D. and
            Howard, R. E. and Hubbard, W. and Jackel, L. D.},
  journal = {Neural Computation},
  title = {Backpropagation Applied to Handwritten Zip Code Recognition},
  year = {1989},
  volume = {1},
  number = {4},
  pages = {541-551},
  doi = {10.1162/neco.1989.1.4.541},
}
@article{vanderpol2020mdp,
  doi = {10.48550/ARXIV.2006.16908},
  url = {https://arxiv.org/abs/2006.16908},
  author = {van der Pol, Elise and Worrall, Daniel E. and van Hoof, Herke and
            Oliehoek, Frans A. and Welling, Max},
  keywords = {Machine Learning (cs.LG), Machine Learning (stat.ML), FOS:
              Computer and information sciences, FOS: Computer and information
              sciences},
  title = {MDP Homomorphic Networks: Group Symmetries in Reinforcement Learning},
  publisher = {arXiv},
  year = {2020},
  copyright = {arXiv.org perpetual, non-exclusive license},
}

@article{ravindran2003smdp,
  title = {SMDP homomorphisms: An algebraic approach to abstraction in semi
           markov decision processes},
  author = {Ravindran, Balaraman},
  year = {2003},
}
@inproceedings{ravindran2001symmetries,
  title = {Symmetries and Model Minimization in Markov Decision Processes},
  author = {Balaraman Ravindran and Andrew G. Barto},
  year = {2001},
}
@article{bellamn1957mdp,
  author = {Richard Bellman},
  title = {A Markovian Decision Process},
  journal = {Indiana Univ. Math. J.},
  fjournal = {Indiana University Mathematics Journal},
  volume = 6,
  year = 1957,
  issue = 4,
  pages = {679--684},
  issn = {0022-2518},
  coden = {IUMJAB},
  mrclass = {},
}
@inproceedings{howard1960dynamic,
  title = {Dynamic Programming and Markov Processes},
  author = {Ronald A. Howard},
  year = {1960},
}
@article{minh2016asynchronous,
  doi = {10.48550/ARXIV.1602.01783},
  url = {https://arxiv.org/abs/1602.01783},
  author = {Mnih, Volodymyr and Badia, Adrià Puigdomènech and Mirza, Mehdi and
            Graves, Alex and Lillicrap, Timothy P. and Harley, Tim and Silver,
            David and Kavukcuoglu, Koray},
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences,
              FOS: Computer and information sciences},
  title = {Asynchronous Methods for Deep Reinforcement Learning},
  publisher = {arXiv},
  year = {2016},
  copyright = {arXiv.org perpetual, non-exclusive license},
}

@article{mnih2013playing,
  title = {Playing atari with deep reinforcement learning},
  author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves,
            Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller,
            Martin},
  journal = {arXiv preprint arXiv:1312.5602},
  year = {2013},
}
@article{lillicrap2015continuous,
  title = {Continuous control with deep reinforcement learning},
  author = {Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and
            Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and
            Wierstra, Daan},
  journal = {arXiv preprint arXiv:1509.02971},
  year = {2015},
}}

@misc{schulman2015highdimensional,
  doi = {10.48550/ARXIV.1506.02438},
  url = {https://arxiv.org/abs/1506.02438},
  author = {Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan,
            Michael and Abbeel, Pieter},
  keywords = {Machine Learning (cs.LG), Robotics (cs.RO), Systems and Control
              (eess.SY), FOS: Computer and information sciences, FOS: Computer
              and information sciences, FOS: Electrical engineering, electronic
              engineering, information engineering, FOS: Electrical engineering,
              electronic engineering, information engineering},
  title = {High-Dimensional Continuous Control Using Generalized Advantage
           Estimation},
  publisher = {arXiv},
  year = {2015},
  copyright = {arXiv.org perpetual, non-exclusive license},
}
@article{silver2016mastering,
  title = {Mastering the game of Go with deep neural networks and tree search},
  author = {David Silver and Aja Huang and Christopher J. Maddison and Arthur
            Guez and Laurent Sifre and George van den Driessche and Julian
            Schrittwieser and Ioannis Antonoglou and Veda Panneershelvam and Marc
            Lanctot and Sander Dieleman and Dominik Grewe and John Nham and Nal
            Kalchbrenner and Ilya Sutskever and Timothy Lillicrap and Madeleine
            Leach and Koray Kavukcuoglu and Thore Graepel and Demis Hassabis},
  year = {2016},
  url = {http://www.nature.com/nature/journal/v529/n7587/full/nature16961.html},
  journal = {Nature},
  pages = {484--503},
  volume = {529},
}
@article{silver2017mastering,
  title = {Mastering chess and shogi by self-play with a general reinforcement
           learning algorithm},
  author = {Silver, David and Hubert, Thomas and Schrittwieser, Julian and
            Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot,
            Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and
            others},
  journal = {arXiv preprint arXiv:1712.01815},
  year = {2017},
}
@article{hafner2023mastering,
  title = {Mastering Diverse Domains through World Models},
  author = {Hafner, Danijar and Pasukonis, Jurgis and Ba, Jimmy and Lillicrap,
            Timothy},
  journal = {arXiv preprint arXiv:2301.04104},
  year = {2023},
}
@article{williams1992simple,
  title = {Simple statistical gradient-following algorithms for connectionist
           reinforcement learning},
  author = {Williams, Ronald J},
  journal = {Reinforcement learning},
  pages = {5--32},
  year = {1992},
  publisher = {Springer},
}
@article{schulman2015high,
  title = {High-dimensional continuous control using generalized advantage
           estimation},
  author = {Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan,
            Michael and Abbeel, Pieter},
  journal = {arXiv preprint arXiv:1506.02438},
  year = {2015},
}
@inproceedings{shculman2015trust,
  title = {Trust Region Policy Optimization},
  author = {Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan,
            Michael and Moritz, Philipp},
  booktitle = {Proceedings of the 32nd International Conference on Machine
               Learning},
  pages = {1889--1897},
  year = {2015},
  editor = {Bach, Francis and Blei, David},
  volume = {37},
  series = {Proceedings of Machine Learning Research},
  address = {Lille, France},
  month = {07--09 Jul},
  publisher = {PMLR},
  pdf = {http://proceedings.mlr.press/v37/schulman15.pdf},
  url = {https://proceedings.mlr.press/v37/schulman15.html},
  abstract = {In this article, we describe a method for optimizing control
              policies, with guaranteed monotonic improvement. By making several
              approximations to the theoretically-justified scheme, we develop a
              practical algorithm, called Trust Region Policy Optimization
              (TRPO). This algorithm is effective for optimizing large nonlinear
              policies such as neural networks. Our experiments demonstrate its
              robust performance on a wide variety of tasks: learning simulated
              robotic swimming, hopping, and walking gaits; and playing Atari
              games using images of the screen as input. Despite its
              approximations that deviate from the theory, TRPO tends to give
              monotonic improvement with little tuning of hyperparameters.},
}
@article{schulman2017proximal,
  title = {Proximal policy optimization algorithms},
  author = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford,
            Alec and Klimov, Oleg},
  journal = {arXiv preprint arXiv:1707.06347},
  year = {2017},
}
@inproceedings{van2016deep,
  title = {Deep reinforcement learning with double q-learning},
  author = {Van Hasselt, Hado and Guez, Arthur and Silver, David},
  booktitle = {Proceedings of the AAAI conference on artificial intelligence},
  volume = {30},
  number = {1},
  year = {2016},
}
@inproceedings{henderson2018deep,
  title = {Deep reinforcement learning that matters},
  author = {Henderson, Peter and Islam, Riashat and Bachman, Philip and Pineau,
            Joelle and Precup, Doina and Meger, David},
  booktitle = {Proceedings of the AAAI conference on artificial intelligence},
  volume = {32},
  number = {1},
  year = {2018},
}
@article{dulac2019challenges,
  title = {Challenges of real-world reinforcement learning},
  author = {Dulac-Arnold, Gabriel and Mankowitz, Daniel and Hester, Todd},
  journal = {arXiv preprint arXiv:1904.12901},
  year = {2019},
}
@book{sutton2018reinforcement,
  title = {Reinforcement learning: An introduction},
  author = {Sutton, Richard S and Barto, Andrew G},
  year = {2018},
}
@article{hafner2020mastering,
  title = {Mastering atari with discrete world models},
  author = {Hafner, Danijar and Lillicrap, Timothy and Norouzi, Mohammad and Ba,
            Jimmy},
  journal = {arXiv preprint arXiv:2010.02193},
  year = {2020},
}
@techreport{wolpert1995no,
  title = {No free lunch theorems for search},
  author = {Wolpert, David H and Macready, William G and others},
  year = {1995},
  institution = {Citeseer},
}
@article{baxter2000model,
  title = {A model of inductive bias learning},
  author = {Baxter, Jonathan},
  journal = {Journal of artificial intelligence research},
  volume = {12},
  pages = {149--198},
  year = {2000},
}
@article{goyal2022inductive,
  title = {Inductive biases for deep learning of higher-level cognition},
  author = {Goyal, Anirudh and Bengio, Yoshua},
  journal = {Proceedings of the Royal Society A},
  volume = {478},
  number = {2266},
  pages = {20210068},
  year = {2022},
  publisher = {The Royal Society},
}

@article{wang2022mathrm,
  title = {$$\backslash$mathrm $\{$SO$\}$(2) $-Equivariant Reinforcement
           Learning},
  author = {Wang, Dian and Walters, Robin and Platt, Robert},
  journal = {arXiv preprint arXiv:2203.04439},
  year = {2022},
}
@article{weiler2019general,
  title = {General e (2)-equivariant steerable cnns},
  author = {Weiler, Maurice and Cesa, Gabriele},
  journal = {Advances in neural information processing systems},
  volume = {32},
  year = {2019},
}
@misc{coumans2021,
  author = {Erwin Coumans and Yunfei Bai},
  title = {PyBullet, a Python module for physics simulation for games, robotics
           and machine learning},
  howpublished = {\url{http://pybullet.org}},
  year = {2016--2021},
}
@article{zhou2020meta,
  title = {Meta-learning symmetries by reparameterization},
  author = {Zhou, Allan and Knowles, Tom and Finn, Chelsea},
  journal = {arXiv preprint arXiv:2007.02933},
  year = {2020},
}
@inproceedings{finn2017model,
  title = {Model-agnostic meta-learning for fast adaptation of deep networks},
  author = {Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
  booktitle = {International conference on machine learning},
  pages = {1126--1135},
  year = {2017},
  organization = {PMLR},
}
@article{van2020plannable,
  title = {Plannable approximations to mdp homomorphisms: Equivariance under
           actions},
  author = {Van der Pol, Elise and Kipf, Thomas and Oliehoek, Frans A and
            Welling, Max},
  journal = {arXiv preprint arXiv:2002.11963},
  year = {2020},
}
@article{fuchs2020se,
  title = {Se (3)-transformers: 3d roto-translation equivariant attention
           networks},
  author = {Fuchs, Fabian and Worrall, Daniel and Fischer, Volker and Welling,
            Max},
  journal = {Advances in neural information processing systems},
  volume = {33},
  pages = {1970--1981},
  year = {2020},
}
@article{jumper2021highly,
  title = {Highly accurate protein structure prediction with AlphaFold},
  author = {Jumper, John and Evans, Richard and Pritzel, Alexander and Green,
            Tim and Figurnov, Michael and Ronneberger, Olaf and Tunyasuvunakool,
            Kathryn and Bates, Russ and {\v{Z}}{\'\i}dek, Augustin and Potapenko,
            Anna and others},
  journal = {Nature},
  volume = {596},
  number = {7873},
  pages = {583--589},
  year = {2021},
  publisher = {Nature Publishing Group},
}
@article{bronstein2021geometric,
  title = {Geometric deep learning: Grids, groups, graphs, geodesics, and gauges
           },
  author = {Bronstein, Michael M and Bruna, Joan and Cohen, Taco and Veli{\v{c}}
            kovi{\'c}, Petar},
  journal = {arXiv preprint arXiv:2104.13478},
  year = {2021},
}
@article{alet2021noether,
  title = {Noether networks: meta-learning useful conserved quantities},
  author = {Alet, Ferran and Doblar, Dylan and Zhou, Allan and Tenenbaum, Josh
            and Kawaguchi, Kenji and Finn, Chelsea},
  journal = {Advances in Neural Information Processing Systems},
  volume = {34},
  pages = {16384--16397},
  year = {2021},
}
@article{mavor2022simple,
  title = {A simple approach for state-action abstraction using a learned mdp
           homomorphism},
  author = {Mavor-Parker, Augustine N and Banino, Andrea and Griffin, Lewis D
            and Barry, Caswell},
  journal = {arXiv preprint arXiv:2209.06356},
  year = {2022},
}
@article{rezaei2022continuous,
  title = {Continuous MDP Homomorphisms and Homomorphic Policy Gradient},
  author = {Rezaei-Shoshtari, Sahand and Zhao, Rosie and Panangaden, Prakash and
            Meger, David and Precup, Doina},
  journal = {Advances in Neural Information Processing Systems},
  volume = {35},
  pages = {20189--20204},
  year = {2022},
}
@article{lu2022discovered,
  title = {Discovered policy optimisation},
  author = {Lu, Chris and Kuba, Jakub and Letcher, Alistair and Metz, Luke and
            Schroeder de Witt, Christian and Foerster, Jakob},
  journal = {Advances in Neural Information Processing Systems},
  volume = {35},
  pages = {16455--16468},
  year = {2022},
}
@inproceedings{osband2020bsuite,
  title = {Behaviour Suite for Reinforcement Learning},
  author = {Osband, Ian and Doron, Yotam and Hessel, Matteo and Aslanides, John
            and Sezener, Eren and Saraiva, Andre and McKinney, Katrina and
            Lattimore, Tor and {Sz}epesv{\'a}ri, Csaba and Singh, Satinder and
            Van Roy, Benjamin and Sutton, Richard and Silver, David and van
            Hasselt, Hado},
  booktitle = {International Conference on Learning Representations},
  year = {2020},
  url = {https://openreview.net/forum?id=rygf-kSYwH},
}
@article{florian2007correct,
  title = {Correct equations for the dynamics of the cart-pole system},
  author = {Florian, Razvan V},
}
@article{barto1983neuronlike,
  title = {Neuronlike adaptive elements that can solve difficult learning
           control problems},
  author = {Barto, Andrew G and Sutton, Richard S and Anderson, Charles W},
  journal = {IEEE transactions on systems, man, and cybernetics},
  number = {5},
  pages = {834--846},
  year = {1983},
  publisher = {IEEE},
}

@article{kirkpatrick2017overcoming,
  title = {Overcoming catastrophic forgetting in neural networks},
  author = {Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and
            Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A and Milan,
            Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska,
            Agnieszka and others},
  journal = {Proceedings of the national academy of sciences},
  volume = {114},
  number = {13},
  pages = {3521--3526},
  year = {2017},
  publisher = {National Acad Sciences},
}
@article{sutton2012dyna,
  title = {Dyna-style planning with linear function approximation and
           prioritized sweeping},
  author = {Sutton, Richard S and Szepesv{\'a}ri, Csaba and Geramifard, Alborz
            and Bowling, Michael P},
  journal = {arXiv preprint arXiv:1206.3285},
  year = {2012},
}
@inproceedings{haarnoja2018soft,
  title = {Soft actor-critic: Off-policy maximum entropy deep reinforcement
           learning with a stochastic actor},
  author = {Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine,
            Sergey},
  booktitle = {International conference on machine learning},
  pages = {1861--1870},
  year = {2018},
  organization = {PMLR},
}
@article{johnston2022symmetry,
  title = {Symmetry and simplicity spontaneously emerge from the algorithmic
           nature of evolution},
  author = {Johnston, Iain G and Dingle, Kamaludin and Greenbury, Sam F and
            Camargo, Chico Q and Doye, Jonathan PK and Ahnert, Sebastian E and
            Louis, Ard A},
  journal = {Proceedings of the National Academy of Sciences},
  volume = {119},
  number = {11},
  pages = {e2113883119},
  year = {2022},
  publisher = {National Acad Sciences},
}
@article{he2022symmetry,
  title = {Symmetry and spatial ability enhance change detection in visuospatial
           structures},
  author = {He, Chuanxiuyue and Rathbun, Zoe and Buonauro, Daniel and Meyerhoff,
            Hauke S and Franconeri, Steven L and Stieff, Mike and Hegarty, Mary},
  journal = {Memory \& Cognition},
  volume = {50},
  number = {6},
  pages = {1186--1200},
  year = {2022},
  publisher = {Springer},
}
@inproceedings{hessel2018rainbow,
  title = {Rainbow: Combining improvements in deep reinforcement learning},
  author = {Hessel, Matteo and Modayil, Joseph and Van Hasselt, Hado and Schaul,
            Tom and Ostrovski, Georg and Dabney, Will and Horgan, Dan and Piot,
            Bilal and Azar, Mohammad and Silver, David},
  booktitle = {Proceedings of the AAAI conference on artificial intelligence},
  volume = {32},
  number = {1},
  year = {2018},
}
@article{van2018deep,
  title = {Deep reinforcement learning and the deadly triad},
  author = {Van Hasselt, Hado and Doron, Yotam and Strub, Florian and Hessel,
            Matteo and Sonnerat, Nicolas and Modayil, Joseph},
  journal = {arXiv preprint arXiv:1812.02648},
  year = {2018},
}
@article{hornik1991approximation,
  title = {Approximation capabilities of multilayer feedforward networks},
  author = {Hornik, Kurt},
  journal = {Neural networks},
  volume = {4},
  number = {2},
  pages = {251--257},
  year = {1991},
  publisher = {Elsevier},
}
@inproceedings{zhao2022integrating,
  title = {Integrating Symmetry into Differentiable Planning with Steerable
           Convolutions},
  author = {Zhao, Linfeng and Zhu, Xupeng and Kong, Lingzhi and Walters, Robin
            and Wong, Lawson LS},
  booktitle = {The Eleventh International Conference on Learning Representations
               },
  year = {2022},
}
@article{park2022learning,
  title = {Learning symmetric embeddings for equivariant world models},
  author = {Park, Jung Yeon and Biza, Ondrej and Zhao, Linfeng and van de Meent,
            Jan Willem and Walters, Robin},
  journal = {arXiv preprint arXiv:2204.11371},
  year = {2022},
}
