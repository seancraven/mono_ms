{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from model_based.train import make_train, HyperParams,  SARSDTuple, make_catch_bce_loss_fn, make_catch_accuracy_loss_fn\n",
    "from model_based.transition_models import CatchModel, CatchEquiModel\n",
    "from model_based.sample_env import make_experience_fn, make_expert_experience_fn\n",
    "import pickle\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import base_rl.higher_order as ho\n",
    "from base_rl.models import ActorCritic\n",
    "import matplotlib\n",
    "from gymnax.environments.bsuite import Catch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = ho.CONFIG\n",
    "cfg[\"ENV\"] = Catch()\n",
    "cfg[\"ENV_PARAMS\"] = Catch().default_params\n",
    "train_fn = jax.jit(ho.make_train(cfg, ActorCritic))\n",
    "result = train_fn(jax.random.PRNGKey(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner_state= result[\"runner_state\"]\n",
    "expert_params = runner_state[0].params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sean/ms_mono/.venv/lib/python3.10/site-packages/jax/_src/numpy/array_methods.py:796: UserWarning: Explicitly requested dtype <class 'jax.numpy.int64'> requested in astype is not available, and will be truncated to dtype int32. To enable more dtypes, set the jax_enable_x64 configuration option or the JAX_ENABLE_X64 shell environment variable. See https://github.com/google/jax#current-gotchas for more.\n",
      "  return getattr(self.aval, name).fun(self, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "num = 2000\n",
    "keys = jax.random.split(jax.random.PRNGKey(42), num)\n",
    "random_data = jax.jit(jax.vmap(make_experience_fn(\"Catch-bsuite\", 500)))(keys)\n",
    "random_data_len = np.prod(random_data.reward.shape)\n",
    "random_data = jax.tree_map(lambda x: x.reshape((random_data_len, -1)), random_data)\n",
    "\n",
    "expert_data = jax.jit(jax.vmap(make_expert_experience_fn(\"Catch-bsuite\", 500, expert_params)))(keys)\n",
    "expert_data_len= np.prod(expert_data.reward.shape)\n",
    "expert_data= jax.tree_map(lambda x: x.reshape((expert_data_len, -1)), expert_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp = HyperParams(model=CatchModel, train_frac=0.8)\n",
    "data = random_data.join(expert_data)\n",
    "data_len = np.prod(data.reward.shape)\n",
    "data = jax.tree_map(lambda x: x.reshape(data_len, -1), data)\n",
    "perm = np.random.permutation(data_len)\n",
    "data = jax.tree_map(lambda x: x.at[perm, ...].get(), data)\n",
    "\n",
    "# non_zero = (data.done ==0).reshape(-1)\n",
    "# data = jax.tree_map(lambda x: x.at[non_zero, ...].get(), data)\n",
    "\n",
    "\n",
    "\n",
    "train_data, val_data = data.partition(hyp.get_train_size(data))\n",
    "filtered_data = train_data.filter_by_action(0)\n",
    "\n",
    "# jax.tree_map(lambda x: print(x.shape), train_data)\n",
    "# jax.tree_map(lambda x: print(x.shape), val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(hyp, train_data, val_data):\n",
    "    train = make_train(hyp, train_data, val_data, loss_function_ho=make_catch_bce_loss_fn, val_loss_function_ho=make_catch_accuracy_loss_fn)\n",
    "    result = train(jax.random.PRNGKey(42))\n",
    "    losses = result[1][0]\n",
    "    return losses.train_loss.reshape(-1), losses.val_loss.reshape(-1), result[0] \n",
    "def get_x(loss, epoch):\n",
    "    return np.linspace(0, epoch, len(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPCH=100\n",
    "hyp = HyperParams(model=CatchModel, train_frac=1, epochs=EPCH, learning_rate=1e-5)\n",
    "hyp_equi = HyperParams(model=CatchEquiModel, train_frac=1, epochs=EPCH, learning_rate=1e-5)\n",
    "hyps = [ hyp, hyp_equi]\n",
    "datas = [train_data, filtered_data, random_data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m sub_sol \u001b[39m=\u001b[39m []\n\u001b[1;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m i, data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(datas):\n\u001b[0;32m----> 8\u001b[0m     train_loss, val_loss, runner_state\u001b[39m=\u001b[39m train_model(hyp, data, val_data)\n\u001b[1;32m      9\u001b[0m     sub_sol\u001b[39m.\u001b[39mappend((train_loss, val_loss))\n\u001b[1;32m     10\u001b[0m     models[(hyp\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, i)] \u001b[39m=\u001b[39mrunner_state \n",
      "Cell \u001b[0;32mIn[21], line 3\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(hyp, train_data, val_data)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain_model\u001b[39m(hyp, train_data, val_data):\n\u001b[1;32m      2\u001b[0m     train \u001b[39m=\u001b[39m make_train(hyp, train_data, val_data, loss_function_ho\u001b[39m=\u001b[39mmake_catch_bce_loss_fn, val_loss_function_ho\u001b[39m=\u001b[39mmake_catch_accuracy_loss_fn)\n\u001b[0;32m----> 3\u001b[0m     result \u001b[39m=\u001b[39m train(jax\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49mPRNGKey(\u001b[39m42\u001b[39;49m))\n\u001b[1;32m      4\u001b[0m     losses \u001b[39m=\u001b[39m result[\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[1;32m      5\u001b[0m     \u001b[39mreturn\u001b[39;00m losses\u001b[39m.\u001b[39mtrain_loss\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), losses\u001b[39m.\u001b[39mval_loss\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), result[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/ms_mono/model_based/model_based/train.py:187\u001b[0m, in \u001b[0;36mmake_train.<locals>.train\u001b[0;34m(rng)\u001b[0m\n\u001b[1;32m    184\u001b[0m optimizer \u001b[39m=\u001b[39m adam(hyper_params\u001b[39m.\u001b[39mlearning_rate)\n\u001b[1;32m    186\u001b[0m _, params_key \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39msplit(rng)\n\u001b[0;32m--> 187\u001b[0m params \u001b[39m=\u001b[39m network\u001b[39m.\u001b[39;49minit(\n\u001b[1;32m    188\u001b[0m     params_key,\n\u001b[1;32m    189\u001b[0m     jnp\u001b[39m.\u001b[39;49mones((state_dim,)),\n\u001b[1;32m    190\u001b[0m     jnp\u001b[39m.\u001b[39;49mones((action_dim,)),\n\u001b[1;32m    191\u001b[0m )\n\u001b[1;32m    192\u001b[0m apply_network \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mvmap(network\u001b[39m.\u001b[39mapply, in_axes\u001b[39m=\u001b[39m(\u001b[39mNone\u001b[39;00m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m))\n\u001b[1;32m    194\u001b[0m train_state \u001b[39m=\u001b[39m TrainState\u001b[39m.\u001b[39mcreate(\n\u001b[1;32m    195\u001b[0m     apply_fn\u001b[39m=\u001b[39mapply_network,\n\u001b[1;32m    196\u001b[0m     params\u001b[39m=\u001b[39mparams,\n\u001b[1;32m    197\u001b[0m     tx\u001b[39m=\u001b[39moptimizer,\n\u001b[1;32m    198\u001b[0m )\n",
      "    \u001b[0;31m[... skipping hidden 9 frame]\u001b[0m\n",
      "File \u001b[0;32m~/ms_mono/model_based/model_based/transition_models.py:188\u001b[0m, in \u001b[0;36mCatchEquiModel.__call__\u001b[0;34m(self, state, action)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[39m@nn\u001b[39m\u001b[39m.\u001b[39mcompact\n\u001b[1;32m    185\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\n\u001b[1;32m    186\u001b[0m     \u001b[39mself\u001b[39m, state: Observation, action: Action\n\u001b[1;32m    187\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[distrax\u001b[39m.\u001b[39mCategorical, distrax\u001b[39m.\u001b[39mCategorical]:\n\u001b[0;32m--> 188\u001b[0m     next_states_stacked \u001b[39m=\u001b[39m _CatchEquiLogits(\n\u001b[1;32m    189\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstate_dim, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhidden_dim, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maction_dim\n\u001b[1;32m    190\u001b[0m     )(state, action)\n\u001b[1;32m    191\u001b[0m     next_state \u001b[39m=\u001b[39m catch_proximal_state_pool(next_states_stacked, state)\n\u001b[1;32m    192\u001b[0m     ball_dist \u001b[39m=\u001b[39m distrax\u001b[39m.\u001b[39mCategorical(logits\u001b[39m=\u001b[39mnext_state\u001b[39m.\u001b[39mat[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, :\u001b[39m45\u001b[39m]\u001b[39m.\u001b[39mget())\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[0;32m~/ms_mono/model_based/model_based/transition_models.py:167\u001b[0m, in \u001b[0;36m_CatchEquiLogits.__call__\u001b[0;34m(self, state, action)\u001b[0m\n\u001b[1;32m    162\u001b[0m state_embedding_layer \u001b[39m=\u001b[39m C2Dense(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden_dim \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m, transform\u001b[39m=\u001b[39mcatch_transform)\n\u001b[1;32m    163\u001b[0m action_embedding_layer \u001b[39m=\u001b[39m C2Dense(\n\u001b[1;32m    164\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden_dim \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m, transform\u001b[39m=\u001b[39mcatch_action_transform\n\u001b[1;32m    165\u001b[0m )\n\u001b[0;32m--> 167\u001b[0m state_embedding \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mrelu(state_embedding_layer(state))\n\u001b[1;32m    168\u001b[0m action_embedding \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mrelu(action_embedding_layer(action))\n\u001b[1;32m    170\u001b[0m concat \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39mconcatenate(\n\u001b[1;32m    171\u001b[0m     [state_embedding\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), action_embedding\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)], axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[1;32m    172\u001b[0m )\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[0;32m~/ms_mono/g_conv/g_conv/c2.py:35\u001b[0m, in \u001b[0;36mC2Dense.__call__\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39m@nn\u001b[39m\u001b[39m.\u001b[39mcompact\n\u001b[1;32m     28\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m     29\u001b[0m     layer \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mDense(\n\u001b[1;32m     30\u001b[0m         features\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures,\n\u001b[1;32m     31\u001b[0m         use_bias\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_bias,\n\u001b[1;32m     32\u001b[0m     )\n\u001b[1;32m     34\u001b[0m     \u001b[39mreturn\u001b[39;00m jnp\u001b[39m.\u001b[39mstack(\n\u001b[0;32m---> 35\u001b[0m         [layer(\u001b[39minput\u001b[39;49m), layer(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(\u001b[39minput\u001b[39m))],\n\u001b[1;32m     36\u001b[0m         axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m     37\u001b[0m     )\u001b[39m.\u001b[39msqueeze()\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[0;32m~/ms_mono/.venv/lib/python3.10/site-packages/flax/linen/linear.py:196\u001b[0m, in \u001b[0;36mDense.__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[39m@compact\u001b[39m\n\u001b[1;32m    187\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, inputs: Array) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Array:\n\u001b[1;32m    188\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Applies a linear transformation to the inputs along the last dimension.\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \n\u001b[1;32m    190\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39m    The transformed input.\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m   kernel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam(\u001b[39m'\u001b[39;49m\u001b[39mkernel\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m    197\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel_init,\n\u001b[1;32m    198\u001b[0m                       (jnp\u001b[39m.\u001b[39;49mshape(inputs)[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m], \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeatures),\n\u001b[1;32m    199\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_dtype)\n\u001b[1;32m    200\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_bias:\n\u001b[1;32m    201\u001b[0m     bias \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam(\u001b[39m'\u001b[39m\u001b[39mbias\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias_init, (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures,),\n\u001b[1;32m    202\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_dtype)\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[0;32m~/ms_mono/.venv/lib/python3.10/site-packages/jax/_src/nn/initializers.py:279\u001b[0m, in \u001b[0;36mvariance_scaling.<locals>.init\u001b[0;34m(key, shape, dtype)\u001b[0m\n\u001b[1;32m    277\u001b[0m dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mcanonicalize_dtype(dtype)\n\u001b[1;32m    278\u001b[0m named_shape \u001b[39m=\u001b[39m core\u001b[39m.\u001b[39mas_named_shape(shape)\n\u001b[0;32m--> 279\u001b[0m fan_in, fan_out \u001b[39m=\u001b[39m _compute_fans(named_shape, in_axis, out_axis, batch_axis)\n\u001b[1;32m    280\u001b[0m \u001b[39mif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfan_in\u001b[39m\u001b[39m\"\u001b[39m: denominator \u001b[39m=\u001b[39m fan_in\n\u001b[1;32m    281\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfan_out\u001b[39m\u001b[39m\"\u001b[39m: denominator \u001b[39m=\u001b[39m fan_out\n",
      "File \u001b[0;32m~/ms_mono/.venv/lib/python3.10/site-packages/jax/_src/nn/initializers.py:185\u001b[0m, in \u001b[0;36m_compute_fans\u001b[0;34m(shape, in_axis, out_axis, batch_axis)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    184\u001b[0m   batch_size \u001b[39m=\u001b[39m math\u001b[39m.\u001b[39mprod([shape[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m batch_axis])\n\u001b[0;32m--> 185\u001b[0m receptive_field_size \u001b[39m=\u001b[39m shape\u001b[39m.\u001b[39;49mtotal \u001b[39m/\u001b[39;49m in_size \u001b[39m/\u001b[39;49m out_size \u001b[39m/\u001b[39m batch_size\n\u001b[1;32m    186\u001b[0m fan_in \u001b[39m=\u001b[39m in_size \u001b[39m*\u001b[39m receptive_field_size\n\u001b[1;32m    187\u001b[0m fan_out \u001b[39m=\u001b[39m out_size \u001b[39m*\u001b[39m receptive_field_size\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "moving_average = lambda x, w: np.convolve(x, np.ones(w), 'valid') / w\n",
    "cs = [\"blue\", \"indigo\"]\n",
    "sol =[]\n",
    "models = {}\n",
    "for hyp, c in zip(hyps, cs):\n",
    "    sub_sol = []\n",
    "    for i, data in enumerate(datas):\n",
    "        train_loss, val_loss, runner_state= train_model(hyp, data, val_data)\n",
    "        sub_sol.append((train_loss, val_loss))\n",
    "        models[(hyp.model.__name__, i)] =runner_state \n",
    "        \n",
    "    sol.append(sub_sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "matplotlib.rcParams.update( {\"text.usetex\": True, \"font.family\": \"serif\",})\n",
    "titles = [\"Expert Policy: All Actions\", \"Expert Policy: Only Left Action\", \"Random Policy\"]\n",
    "fig, ax = plt.subplots(2, 3, figsize=(20, 10))\n",
    "for sub_sol, hyp, c in zip(sol, hyps, cs):\n",
    "    for i, ((train_loss, val_loss), tit) in enumerate(zip(sub_sol, titles)):\n",
    "        train_loss= moving_average(train_loss, 10)\n",
    "        ax[0, i].semilogy(get_x(train_loss, hyp.epochs),train_loss, label=f\"{hyp.model.__name__} Train\", color=c, alpha = 0.3)\n",
    "        if tit == \"Random Policy\":\n",
    "            ax[1, i].plot(get_x(val_loss, hyp.epochs), val_loss, label=f\"{hyp.model.__name__} Expert Policy Validation\", color=c, linestyle=\"--\")\n",
    "        else: \n",
    "            ax[1, i].plot(get_x(val_loss, hyp.epochs), val_loss, label=f\"{hyp.model.__name__} Val\", color=c, linestyle=\"--\")\n",
    "        ax[0, i].legend(loc=\"lower left\")\n",
    "        ax[0, i].set_xlabel(\"Epochs\")\n",
    "        ax[1, i].set_xlabel(\"Epochs\")\n",
    "        ax[0, i].set_ylabel(\"Cross Entropy Loss\")\n",
    "        ax[1, i].set_ylabel(\"Validation Accuracy\")\n",
    "        ax[0, i].set_title(tit)\n",
    "        ax[0, i].set_xlim(0, EPCH)\n",
    "        ax[1, i].set_ylim(0, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = jax.random.PRNGKey(42)\n",
    "key = jax.random.split(rng, 500)\n",
    "train = jax.jit(ho.make_train(ho.CONFIG, ActorCritic))\n",
    "\n",
    "result = train(rng)\n",
    "runner_state= result[\"runner_state\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catch Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from base_rl.wrappers import FlattenObservationWrapper\n",
    "env = FlattenObservationWrapper(Catch())\n",
    "env_params = env.default_params\n",
    "ts = models[(\"CatchModel\", 2)][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.61859995\n"
     ]
    }
   ],
   "source": [
    "def _accuracy(ball_dist, paddle_dist, next_state):\n",
    "    ball_pred = jnp.zeros_like(ball_dist.probs).at[ball_dist.mode()].set(1.0)\n",
    "    paddle_pred = (\n",
    "        jnp.zeros_like(paddle_dist.probs).at[paddle_dist.mode()].set(1.0)\n",
    "    )\n",
    "    pred = jnp.concatenate(\n",
    "        [\n",
    "            ball_pred.reshape(45),\n",
    "            paddle_pred.reshape(5),\n",
    "        ],\n",
    "        axis=0,\n",
    "    )\n",
    "    accuracy = pred == next_state\n",
    "    return accuracy.all()\n",
    "# def sample_action(key):\n",
    "#     action = env.sample_action(key)\n",
    "#     return action\n",
    "    \n",
    "\n",
    "accs = []\n",
    "num_envs = 100\n",
    "single_key = jax.random.PRNGKey(0)\n",
    "key = jax.random.split(single_key, num_envs)\n",
    "obs, env_state = jax.vmap(env.reset, in_axes=(0, None))(key, env_params)\n",
    "aply = ts.apply_fn\n",
    "other_acc = []\n",
    "policy_aply = jax.vmap(ActorCritic(3).apply, in_axes =(None, 0))\n",
    "\n",
    "for i in range(100):\n",
    "    _, single_key = jax.random.split(single_key)\n",
    "    # action = jax.random.randint(single_key, minval=0, maxval=3, shape=(num_envs,))\n",
    "    action = policy_aply(expert_params, obs)[0].sample(seed=single_key)\n",
    "    ball_dist, pad_dist = aply(ts.params, obs, action)\n",
    "    next_obs, env_state, rew, done, info = jax.vmap(env.step)(key, env_state, action)\n",
    "\n",
    "    prediction = jax.vmap(_accuracy)(ball_dist, pad_dist, next_obs)\n",
    "    obs = next_obs\n",
    "    accs.append(prediction.mean())\n",
    "\n",
    "print(jnp.stack(accs).mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
